{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a2acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1172fb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 542 reviews\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/cleaned/cleaned_reviews_general.csv\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"Error: File not found at {DATA_PATH}\")\n",
    "else:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(DATA_PATH, encoding='utf-8-sig')\n",
    "    print(f\"Successfully loaded {len(df):,} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35bbd40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES\n",
      "           Column  Missing  Percent\n",
      "           rating        0      0.0\n",
      "        sentiment        0      0.0\n",
      "    comment_clean        0      0.0\n",
      "sentiment_encoded        0      0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"MISSING VALUES\")\n",
    "\n",
    "# For rating column, count NaN values + 0 values as missing\n",
    "# For other columns, count only NaN values\n",
    "missing_counts = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    if column == 'rating':\n",
    "        # Count NaN + 0 values for rating\n",
    "        nan_count = df[column].isna().sum()\n",
    "        zero_count = (df[column] == 0).sum()\n",
    "        missing_counts[column] = nan_count + zero_count\n",
    "    else:\n",
    "        # Count only NaN for other columns\n",
    "        missing_counts[column] = df[column].isna().sum()\n",
    "\n",
    "# Convert to Series\n",
    "missing = pd.Series(missing_counts)\n",
    "missing_percent = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing': missing.values,\n",
    "    'Percent': missing_percent.values\n",
    "})\n",
    "\n",
    "print(missing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970fdba",
   "metadata": {},
   "source": [
    "## drop emty comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73881c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['comment_clean'])\n",
    "df = df[df['comment_clean'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec565d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES\n",
      "           Column  Missing  Percent\n",
      "           rating        0      0.0\n",
      "        sentiment        0      0.0\n",
      "    comment_clean        0      0.0\n",
      "sentiment_encoded        0      0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"MISSING VALUES\")\n",
    "\n",
    "# For rating column, count NaN values + 0 values as missing\n",
    "# For other columns, count only NaN values\n",
    "missing_counts = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    if column == 'rating':\n",
    "        # Count NaN + 0 values for rating\n",
    "        nan_count = df[column].isna().sum()\n",
    "        zero_count = (df[column] == 0).sum()\n",
    "        missing_counts[column] = nan_count + zero_count\n",
    "    else:\n",
    "        # Count only NaN for other columns\n",
    "        missing_counts[column] = df[column].isna().sum()\n",
    "\n",
    "# Convert to Series\n",
    "missing = pd.Series(missing_counts)\n",
    "missing_percent = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing': missing.values,\n",
    "    'Percent': missing_percent.values\n",
    "})\n",
    "\n",
    "print(missing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed67d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrob = df[['comment_clean', 'sentiment_encoded']]\n",
    "dfrob = dfrob.rename(columns={'comment_clean': 'text', 'sentiment_encoded': 'label'})\n",
    "dfrob = dfrob.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969b5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrob.to_csv(\"../data/cleaned/finetuning_reviews_general.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd058ff6",
   "metadata": {},
   "source": [
    "## NOTE pour seulement 560 commentaires, il est souvent plus efficace d’utiliser distilRoBERTa ou de fine-tuner uniquement la tête de classification pour éviter le surapprentissage et réduire le temps d’entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53e9ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 542 reviews\n",
      "Distribution des labels :\n",
      "label\n",
      "2    375\n",
      "0    118\n",
      "1     49\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "2    69.188192\n",
      "0    21.771218\n",
      "1     9.040590\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "DATA_PATH = \"../data/cleaned/finetuning_reviews_general.csv\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"Error: File not found at {DATA_PATH}\")\n",
    "else:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(DATA_PATH, encoding='utf-8-sig')\n",
    "    print(f\"Successfully loaded {len(df):,} reviews\")\n",
    "\n",
    "print(\"Distribution des labels :\")\n",
    "print(df['label'].value_counts())        # nombre par classe\n",
    "print(df['label'].value_counts(normalize=True) * 100)  # pourcentages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec13000",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2831c659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING TERMINÉ\n",
      "Train set : (433, 2)\n",
      "Test set  : (109, 2)\n",
      "\n",
      "Répartition des classes – Train :\n",
      "label\n",
      "2    300\n",
      "0     94\n",
      "1     39\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Répartition des classes – Test :\n",
      "label\n",
      "2    75\n",
      "0    24\n",
      "1    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "os.makedirs(\"../data/cleaned/finetuning-splits\", exist_ok=True)\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# 4. Faire le split train/test (stratifié)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 5. Reconstruire des DataFrames\n",
    "train_df = pd.DataFrame({\"text\": X_train, \"label\": y_train})\n",
    "test_df = pd.DataFrame({\"text\": X_test, \"label\": y_test})\n",
    "\n",
    "# 6. Enregistrer les splits en CSV\n",
    "train_path = \"../data/cleaned/finetuning-splits/train_set.csv\"\n",
    "test_path = \"../data/cleaned/finetuning-splits/test_set.csv\"\n",
    "\n",
    "train_df.to_csv(train_path, index=False, encoding='utf-8-sig')\n",
    "test_df.to_csv(test_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 7. Affichage des informations\n",
    "print(\"SPLITTING TERMINÉ\")\n",
    "print(f\"Train set : {train_df.shape}\")\n",
    "print(f\"Test set  : {test_df.shape}\\n\")\n",
    "\n",
    "print(\"Répartition des classes – Train :\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "print(\"\\nRépartition des classes – Test :\")\n",
    "print(test_df[\"label\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
